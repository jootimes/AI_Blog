<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>[뉴스요약#1] "챗GPT에게 물어보고 그대로 기사 써도 될까?"</title>
</head>
<body>
    <h1>[뉴스요약#1] "챗GPT에게 물어보고 그대로 기사 써도 될까?"</h1>
    <p>챗GPT가 범용 딥러닝AI 기술의 강력함을 체험시켜주면서 언론계에서도 이를 사용한 기사들이 많이 나오고 있다. 예를 들어 "챗GPT에게 물어봤더니 ..." 로 시작하는 기사들이다. AI가 사람보다 덜 편향적이고 정확할 것이라는 막연한 믿음이 AI의 답변을 사실로 오인시킬 가능성이 있는 것으로 보여 우려스럽다.</p>
    <p>동아일보 <챗GPT도 아는데 이재명만 모른다>(2/27 김지현 기자)는 논쟁적 주제인 '이재명 더불어민주당 대표가 불체포특권을 포기해야 하는지' 여부를 챗GPT에 질문하고, "가장 중립적인 의견을 가진 전문가에게 의견을 묻고 조언을 구했다"며 챗GPT의 답변을 소개했다. 하지만 챗GPT는 자연어 알고리즘에 따라 '가장 그럴 듯한 문장'을 지어낼 뿐 가치판단을 할 수 있다고는 할 수 없다. 질문에 따라 얼마든지 답을 유도하는 것도 가능하다. 또 동아일보처럼 챗GPT의 답변을 "중립적 전문가"로 소개하지는 않지만, 비슷한 유형의 기사는 늘고 있다. 흥미성 질문도 있지만 '간호법 제정', '인구감소 영향', '출산율 감소 대책', '카카오 SM인수' 등 심층적 판단이 필요한 주제를 다루는 경우도 많은걸로 보인다.</p>
    <p>챗GPT의 답변을 그대로 가져오는 것이 아닌 기자 스스로 그 진위를 검증하고 보도  가치를 판단하는 과정을 거쳐야 하는 것은 당연한 수순이다. 또한 이러한 내용들은 챗GPT 없이 기자 스스로의 검증을 통해서만으로도 작성할 수 있는 기사라고 생각할 수 있다. 아직은 기사의 주요 내용을 챗GPT에게 맡기기에는 시기상조로 보인다. AI의 한계를 독자에게 정확히 인식시키고 오해의 소지를 줄이는 보도 방식에 대해 많은 고민이 필요하다.</p>
</body>
</html>
